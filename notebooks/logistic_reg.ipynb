{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (100, 100)\n",
      "X example [ 0.74412993 -1.05462399 -1.14395605 -0.867277   -0.32781437  2.98354855\n",
      " -0.65535973 -1.02628784 -0.17413571 -0.85936728 -1.11886663  0.08209197\n",
      " -0.77269333  0.29027634  0.27869535 -1.06614616 -0.41135708  2.23390804\n",
      "  0.58007668  0.7996253  -0.21301315  0.22148628 -2.23110119 -1.74484248\n",
      "  0.61165814 -0.54803421  0.84912473  0.16417913 -0.1182921   0.79508234\n",
      " -0.35347602  2.11172162 -0.73374603  0.37512716 -2.24698566  1.09054386\n",
      "  0.07711984  2.09803854 -0.01773146 -0.44279201  1.23148034  0.60439517\n",
      "  1.06866797  0.35697025 -0.45395715  2.08659551 -0.42984696  0.57514958\n",
      "  2.00445117 -0.68890385 -1.6407538  -2.25972271  1.57361877  0.18531059\n",
      "  0.47168033  1.27524396 -0.37071767  0.32125645  0.34909791  1.36067328\n",
      "  0.99613073 -1.10069499  0.46411016 -1.29066336  1.86571388  1.2718142\n",
      " -1.00514275 -0.41467908 -0.98619969 -1.53628655 -0.19590851  0.24877193\n",
      " -0.13015768  0.78244126 -0.14173945 -1.55440867  0.87510995  0.97154984\n",
      " -2.45914188  1.67750194 -1.669842    0.42809259 -0.36725202 -0.54549839\n",
      " -1.23838116  2.21520618 -0.58793099  0.96693625  1.07442324  0.11424021\n",
      " -0.56788079 -1.51194961  0.64597818 -0.49230964  0.17367334  0.24280719\n",
      " -0.36158472  0.14412424 -0.37395217  1.43136775]\n",
      "y shape (100,)\n",
      "y example 2\n"
     ]
    }
   ],
   "source": [
    "n_features = 100\n",
    "n_observations = 100\n",
    "\n",
    "X = np.random.randn(n_observations, n_features)\n",
    "y = np.random.randint(0, 3, n_observations)\n",
    "\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"X example\", X[0])\n",
    "print(\"y shape\", y.shape)\n",
    "print(\"y example\", y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/log_reg_model.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "dump(clf, \"models/log_reg_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "def execution_time(process):\n",
    "    \"\"\" Calculates the execution time of a function \"\"\"\n",
    "    start_time = time.time()\n",
    "    (lambda: process)()\n",
    "    end_time = time.time()\n",
    "    return (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.00s\n",
      "File size: 3.205 KB\n",
      "Test rows: 10.0 million\n"
     ]
    }
   ],
   "source": [
    "# Check file size\n",
    "\n",
    "test_rows = 10000000\n",
    "\n",
    "X_test = np.random.rand(test_rows, n_features)\n",
    "\n",
    "inference_time = execution_time(clf.predict(X_test))\n",
    "weights_size = Path(\"models/log_reg_model.joblib\").stat().st_size\n",
    "\n",
    "print(f\"Inference time: {inference_time:.2f}s\")\n",
    "print(f\"File size: {weights_size / 1000} KB\")\n",
    "print(f\"Test rows: {(test_rows / 1000000)} million\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model as ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, n_features]))]\n",
    "onx = convert_sklearn(clf, initial_types=initial_type)\n",
    "with open(\"models/log_reg_model.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(\"models/log_reg_model.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "X_test_onnx = X_test.astype(np.float32)\n",
    "\n",
    "pred_onx = sess.run([label_name], {input_name: X_test_onnx})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.00s\n",
      "File size: 2.139 KB\n",
      "Test rows: 10.0 million\n"
     ]
    }
   ],
   "source": [
    "test_rows = 10000000\n",
    "\n",
    "X_test = np.random.rand(test_rows, 4)\n",
    "\n",
    "inference_time = execution_time(lambda: sess.run([label_name], {input_name: X_test_onnx}))\n",
    "weights_size = Path(\"models/log_reg_model.onnx\").stat().st_size\n",
    "\n",
    "print(f\"Inference time: {inference_time:.2f}s\")\n",
    "print(f\"File size: {weights_size / 1000} KB\")\n",
    "print(f\"Test rows: {(test_rows / 1000000)} million\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92f6c8b6bdf7ebb20c93336518ddb8fd8dee2042dce8e5033c2591f230ecc507"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('onnx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
